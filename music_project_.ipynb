{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MVNi_YMySP9N",
        "outputId": "8e34c0a5-b259-48ee-f9da-c022af57505e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcRr7CXcP7GT",
        "outputId": "4aa3ef1b-4a37-4931-a1d7-3e20f57031fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.2.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.2-py2.py3-none-any.whl size=281824025 sha256=225b731bc55d673840276a1b53fa1a7bc528527789d19443fda562883e59ea27\n",
            "  Stored in directory: /root/.cache/pip/wheels/6c/e3/9b/0525ce8a69478916513509d43693511463c6468db0de237c86\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import isnan, when,mean,count, col,desc,year, quarter, when,lit, to_date, to_timestamp, concat, avg,countDistinct\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.sql.functions import regexp_replace\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating Spark and setting a name for the application\n",
        "spark=SparkSession.builder.appName('Project').config(\"spark.driver.memory\", \"4g\").getOrCreate()\n",
        "conf = spark.sparkContext.getConf()\n",
        "for key, value in conf.getAll():\n",
        "    print(f\"{key} = {value}\")"
      ],
      "metadata": {
        "id": "h2gyyuywRdWC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec0752e6-f769-4c86-ea94-4b616e4d55ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spark.driver.extraJavaOptions = -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED\n",
            "spark.driver.port = 44261\n",
            "spark.driver.memory = 4g\n",
            "spark.executor.id = driver\n",
            "spark.app.submitTime = 1678797657386\n",
            "spark.app.startTime = 1678797657534\n",
            "spark.driver.host = d2028b7965c8\n",
            "spark.app.id = local-1678797658779\n",
            "spark.rdd.compress = True\n",
            "spark.executor.extraJavaOptions = -XX:+IgnoreUnrecognizedVMOptions --add-opens=java.base/java.lang=ALL-UNNAMED --add-opens=java.base/java.lang.invoke=ALL-UNNAMED --add-opens=java.base/java.lang.reflect=ALL-UNNAMED --add-opens=java.base/java.io=ALL-UNNAMED --add-opens=java.base/java.net=ALL-UNNAMED --add-opens=java.base/java.nio=ALL-UNNAMED --add-opens=java.base/java.util=ALL-UNNAMED --add-opens=java.base/java.util.concurrent=ALL-UNNAMED --add-opens=java.base/java.util.concurrent.atomic=ALL-UNNAMED --add-opens=java.base/sun.nio.ch=ALL-UNNAMED --add-opens=java.base/sun.nio.cs=ALL-UNNAMED --add-opens=java.base/sun.security.action=ALL-UNNAMED --add-opens=java.base/sun.util.calendar=ALL-UNNAMED --add-opens=java.security.jgss/sun.security.krb5=ALL-UNNAMED\n",
            "spark.serializer.objectStreamReset = 100\n",
            "spark.master = local[*]\n",
            "spark.submit.pyFiles = \n",
            "spark.submit.deployMode = client\n",
            "spark.app.name = Project\n",
            "spark.ui.showConsoleProgress = true\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "music = spark.read.csv(\"/content/drive/MyDrive/Project_Data/final_spotify.csv\",inferSchema=True, header=True)"
      ],
      "metadata": {
        "id": "v3LVZtgIRnal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the dataset\n",
        "music.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6QOQr7sSJLd",
        "outputId": "a46cdf9d-e62b-46ed-ff6e-92659443f199"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+--------------------+--------------------+--------------------+----------+-----------+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+-----------+--------------------+\n",
            "|index_id|            track_id|             artists|          album_name|          track_name|popularity|duration_ms|explicit|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|  tempo|time_signature|track_genre|spotify_release_date|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+----------+-----------+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+-----------+--------------------+\n",
            "|       0|5SuOikwiRyPMVoIQD...|         Gen Hoshino|              Comedy|              Comedy|        73|     230666|   FALSE|       0.676| 0.461|  1|  -6.746|   0|      0.143|      0.0322|         1.01E-6|   0.358|  0.715| 87.917|           4.0|   acoustic|          2016-12-31|\n",
            "|       1|4qPNDBW1i3p13qLCt...|        Ben Woodward|    Ghost (Acoustic)|    Ghost - Acoustic|        55|     149610|   FALSE|        0.42| 0.166|  1| -17.235|   1|     0.0763|       0.924|         5.56E-6|   0.101|  0.267| 77.489|           4.0|   acoustic|          2009-02-23|\n",
            "|       2|1iJBSr7s7jYXzM8EG...|Ingrid Michaelson...|      To Begin Again|      To Begin Again|        57|     210826|   FALSE|       0.438| 0.359|  0|  -9.734|   1|     0.0557|        0.21|             0.0|   0.117|   0.12| 76.332|           4.0|   acoustic|          2014-03-26|\n",
            "|       3|6lfxq3CG4xtTiEg7o...|        Kina Grannis|Crazy Rich Asians...|Can't Help Fallin...|        71|     201933|   FALSE|       0.266|0.0596|  0| -18.515|   1|     0.0363|       0.905|         7.07E-5|   0.132|  0.143| 181.74|           3.0|   acoustic|          2013-02-01|\n",
            "|       4|5vjLSffimiIP26QG5...|    Chord Overstreet|             Hold On|             Hold On|        82|     198853|   FALSE|       0.618| 0.443|  2|  -9.681|   1|     0.0526|       0.469|             0.0|  0.0829|  0.167|119.949|           4.0|   acoustic|          2011-12-14|\n",
            "|       5|01MVOl9KtVTNfFiBU...|        Tyrone Wells|Days I Will Remember|Days I Will Remember|        58|     214240|   FALSE|       0.688| 0.481|  6|  -8.807|   1|      0.105|       0.289|             0.0|   0.189|  0.666| 98.017|           4.0|   acoustic|          2013-08-31|\n",
            "|       6|6Vc5wAMmXdKIAM7WU...|A Great Big World...|Is There Anybody ...|       Say Something|        74|     229400|   FALSE|       0.407| 0.147|  2|  -8.822|   1|     0.0355|       0.857|         2.89E-6|  0.0913| 0.0765|141.284|           3.0|   acoustic|          2020-08-23|\n",
            "|       7|1EzrEOXmMH3G43AXT...|          Jason Mraz|We Sing. We Dance...|           I'm Yours|        80|     242946|   FALSE|       0.703| 0.444| 11|  -9.331|   1|     0.0417|       0.559|             0.0|  0.0973|  0.712| 150.96|           4.0|   acoustic|          2019-08-29|\n",
            "|       8|0IktbUcnAGrvD03AW...|Jason Mraz;Colbie...|We Sing. We Dance...|               Lucky|        74|     189613|   FALSE|       0.625| 0.414|  0|    -8.7|   1|     0.0369|       0.294|             0.0|   0.151|  0.669|130.088|           4.0|   acoustic|          2018-03-18|\n",
            "|       9|7k9GuJYLp2AzqokyE...|      Ross Copperman|              Hunger|              Hunger|        56|     205594|   FALSE|       0.442| 0.632|  1|   -6.77|   1|     0.0295|       0.426|         0.00419|  0.0735|  0.196| 78.899|           4.0|   acoustic|          2011-11-21|\n",
            "|      10|4mzP5mHkRvGxdhdGd...|        Zack Tabudlo|             Episode|Give Me Your Forever|        74|     244800|   FALSE|       0.627| 0.363|  8|  -8.127|   1|     0.0291|       0.279|             0.0|  0.0928|  0.301| 99.905|           4.0|   acoustic|          2019-01-05|\n",
            "|      11|5ivF4eQBqJiVL5IAE...|          Jason Mraz|Love Is a Four Le...|     I Won't Give Up|        69|     240165|   FALSE|       0.483| 0.303|  4| -10.058|   1|     0.0429|       0.694|             0.0|   0.115|  0.139|133.406|           3.0|   acoustic|          2018-09-30|\n",
            "|      12|4ptDJbJl35d7gQfeN...|            Dan Berk|                Solo|                Solo|        52|     198712|   FALSE|       0.489| 0.314|  7|  -9.245|   0|     0.0331|       0.749|             0.0|   0.113|  0.607|124.234|           4.0|   acoustic|          2016-05-11|\n",
            "|      13|0X9MxHR1rTkEHDjp9...|       Anna Hamilton|            Bad Liar|            Bad Liar|        62|     248448|   FALSE|       0.691| 0.234|  3|  -6.441|   1|     0.0285|       0.777|             0.0|    0.12|  0.209| 87.103|           4.0|   acoustic|          2019-05-29|\n",
            "|      14|4LbWtBkN82ZRhz9jq...|Chord Overstreet;...|     Hold On (Remix)|     Hold On - Remix|        56|     188133|   FALSE|       0.755|  0.78|  2|  -6.084|   1|     0.0327|       0.124|         2.83E-5|   0.121|  0.387|120.004|           4.0|   acoustic|          2014-09-30|\n",
            "|      15|1KHdq8NK9QxnGjdXb...|         Landon Pigg|   The Boy Who Never|Falling in Love a...|        58|     244986|   FALSE|       0.489| 0.561|  4|  -7.933|   1|     0.0274|         0.2|         4.56E-5|   0.179|  0.238| 83.457|           3.0|   acoustic|          2017-06-20|\n",
            "|      16|6xKeQgzfjixSUld14...|Andrew Foy;Renee Foy|ily (i love you b...|ily (i love you b...|        56|     129750|   FALSE|       0.706| 0.112|  2| -18.098|   1|     0.0391|       0.827|         4.03E-6|   0.125|  0.414|110.154|           4.0|   acoustic|          2018-03-20|\n",
            "|      17|4Yo0igmcoNyat1sec...|Andrew Foy;Renee Foy|         At My Worst|         At My Worst|        54|     169728|   FALSE|       0.795|0.0841| 10|  -18.09|   0|     0.0461|       0.742|         1.17E-5|  0.0853|  0.609| 91.803|           4.0|   acoustic|          2013-10-23|\n",
            "|      18|2qLMf6TuEC3ruGJg4...|Jason Mraz;Colbie...|We Sing. We Dance...|               Lucky|        68|     189613|   FALSE|       0.625| 0.414|  0|    -8.7|   1|     0.0369|       0.294|             0.0|   0.151|  0.669|130.088|           4.0|   acoustic|          2015-01-14|\n",
            "|      19|6CgNoAbFJ4Q4Id4Ej...|Boyce Avenue;Bea ...|Cover Sessions, V...|          Photograph|        67|     260186|   FALSE|       0.717|  0.32|  3|  -8.393|   1|     0.0283|        0.83|             0.0|   0.107|  0.322|107.946|           4.0|   acoustic|          2017-11-30|\n",
            "+--------+--------------------+--------------------+--------------------+--------------------+----------+-----------+--------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+-----------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "by overlooking at the above data we can drop columns such as [\"track_id\",\"track_name\",\"explicit\",\"spotify_release_date\"] because they have no business with our target variable"
      ],
      "metadata": {
        "id": "s4xjjGmKlx-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "music = music.drop(\"track_id\",\"track_name\",\"explicit\",\"spotify_release_date\")\n",
        "music.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UM_YFiZDmwP6",
        "outputId": "1a414d16-3275-4798-a84b-981c30022a25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------+--------------------+----------+-----------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+-----------+\n",
            "|index_id|             artists|          album_name|popularity|duration_ms|danceability|energy|key|loudness|mode|speechiness|acousticness|instrumentalness|liveness|valence|  tempo|time_signature|track_genre|\n",
            "+--------+--------------------+--------------------+----------+-----------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+-----------+\n",
            "|       0|         Gen Hoshino|              Comedy|        73|     230666|       0.676| 0.461|  1|  -6.746|   0|      0.143|      0.0322|         1.01E-6|   0.358|  0.715| 87.917|           4.0|   acoustic|\n",
            "|       1|        Ben Woodward|    Ghost (Acoustic)|        55|     149610|        0.42| 0.166|  1| -17.235|   1|     0.0763|       0.924|         5.56E-6|   0.101|  0.267| 77.489|           4.0|   acoustic|\n",
            "|       2|Ingrid Michaelson...|      To Begin Again|        57|     210826|       0.438| 0.359|  0|  -9.734|   1|     0.0557|        0.21|             0.0|   0.117|   0.12| 76.332|           4.0|   acoustic|\n",
            "|       3|        Kina Grannis|Crazy Rich Asians...|        71|     201933|       0.266|0.0596|  0| -18.515|   1|     0.0363|       0.905|         7.07E-5|   0.132|  0.143| 181.74|           3.0|   acoustic|\n",
            "|       4|    Chord Overstreet|             Hold On|        82|     198853|       0.618| 0.443|  2|  -9.681|   1|     0.0526|       0.469|             0.0|  0.0829|  0.167|119.949|           4.0|   acoustic|\n",
            "|       5|        Tyrone Wells|Days I Will Remember|        58|     214240|       0.688| 0.481|  6|  -8.807|   1|      0.105|       0.289|             0.0|   0.189|  0.666| 98.017|           4.0|   acoustic|\n",
            "|       6|A Great Big World...|Is There Anybody ...|        74|     229400|       0.407| 0.147|  2|  -8.822|   1|     0.0355|       0.857|         2.89E-6|  0.0913| 0.0765|141.284|           3.0|   acoustic|\n",
            "|       7|          Jason Mraz|We Sing. We Dance...|        80|     242946|       0.703| 0.444| 11|  -9.331|   1|     0.0417|       0.559|             0.0|  0.0973|  0.712| 150.96|           4.0|   acoustic|\n",
            "|       8|Jason Mraz;Colbie...|We Sing. We Dance...|        74|     189613|       0.625| 0.414|  0|    -8.7|   1|     0.0369|       0.294|             0.0|   0.151|  0.669|130.088|           4.0|   acoustic|\n",
            "|       9|      Ross Copperman|              Hunger|        56|     205594|       0.442| 0.632|  1|   -6.77|   1|     0.0295|       0.426|         0.00419|  0.0735|  0.196| 78.899|           4.0|   acoustic|\n",
            "|      10|        Zack Tabudlo|             Episode|        74|     244800|       0.627| 0.363|  8|  -8.127|   1|     0.0291|       0.279|             0.0|  0.0928|  0.301| 99.905|           4.0|   acoustic|\n",
            "|      11|          Jason Mraz|Love Is a Four Le...|        69|     240165|       0.483| 0.303|  4| -10.058|   1|     0.0429|       0.694|             0.0|   0.115|  0.139|133.406|           3.0|   acoustic|\n",
            "|      12|            Dan Berk|                Solo|        52|     198712|       0.489| 0.314|  7|  -9.245|   0|     0.0331|       0.749|             0.0|   0.113|  0.607|124.234|           4.0|   acoustic|\n",
            "|      13|       Anna Hamilton|            Bad Liar|        62|     248448|       0.691| 0.234|  3|  -6.441|   1|     0.0285|       0.777|             0.0|    0.12|  0.209| 87.103|           4.0|   acoustic|\n",
            "|      14|Chord Overstreet;...|     Hold On (Remix)|        56|     188133|       0.755|  0.78|  2|  -6.084|   1|     0.0327|       0.124|         2.83E-5|   0.121|  0.387|120.004|           4.0|   acoustic|\n",
            "|      15|         Landon Pigg|   The Boy Who Never|        58|     244986|       0.489| 0.561|  4|  -7.933|   1|     0.0274|         0.2|         4.56E-5|   0.179|  0.238| 83.457|           3.0|   acoustic|\n",
            "|      16|Andrew Foy;Renee Foy|ily (i love you b...|        56|     129750|       0.706| 0.112|  2| -18.098|   1|     0.0391|       0.827|         4.03E-6|   0.125|  0.414|110.154|           4.0|   acoustic|\n",
            "|      17|Andrew Foy;Renee Foy|         At My Worst|        54|     169728|       0.795|0.0841| 10|  -18.09|   0|     0.0461|       0.742|         1.17E-5|  0.0853|  0.609| 91.803|           4.0|   acoustic|\n",
            "|      18|Jason Mraz;Colbie...|We Sing. We Dance...|        68|     189613|       0.625| 0.414|  0|    -8.7|   1|     0.0369|       0.294|             0.0|   0.151|  0.669|130.088|           4.0|   acoustic|\n",
            "|      19|Boyce Avenue;Bea ...|Cover Sessions, V...|        67|     260186|       0.717|  0.32|  3|  -8.393|   1|     0.0283|        0.83|             0.0|   0.107|  0.322|107.946|           4.0|   acoustic|\n",
            "+--------+--------------------+--------------------+----------+-----------+------------+------+---+--------+----+-----------+------------+----------------+--------+-------+-------+--------------+-----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "in the dataset there is a column name \"instrumentalness\" whose values needs to be transformed for further operations"
      ],
      "metadata": {
        "id": "3HFgEWuRoXyg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, format_number\n",
        "music = music.drop(\"instrumentalness_decimal\")\n",
        "music = music.withColumn(\"instrumentalness_decimal\", format_number(col(\"instrumentalness\"), 20))\n",
        "music = music.drop(\"instrumentalness\")\n",
        "music.show(1,truncate = False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlLOwwS7oId_",
        "outputId": "68069f0c-7d20-444b-b789-17e7b59cbf52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----------+----------+----------+-----------+------------+------+---+--------+----+-----------+------------+--------+-------+------+--------------+-----------+------------------------+\n",
            "|index_id|artists    |album_name|popularity|duration_ms|danceability|energy|key|loudness|mode|speechiness|acousticness|liveness|valence|tempo |time_signature|track_genre|instrumentalness_decimal|\n",
            "+--------+-----------+----------+----------+-----------+------------+------+---+--------+----+-----------+------------+--------+-------+------+--------------+-----------+------------------------+\n",
            "|0       |Gen Hoshino|Comedy    |73        |230666     |0.676       |0.461 |1  |-6.746  |0   |0.143      |0.0322      |0.358   |0.715  |87.917|4.0           |acoustic   |0.00000101000000000000  |\n",
            "+--------+-----------+----------+----------+-----------+------------+------+---+--------+----+-----------+------------+--------+-------+------+--------------+-----------+------------------------+\n",
            "only showing top 1 row\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "music.select(\"instrumentalness_decimal\").show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtKhCS2fJDS5",
        "outputId": "c3bf814d-52ab-4eba-f63f-27a2177a33ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------+\n",
            "|instrumentalness_decimal|\n",
            "+------------------------+\n",
            "|0.00000101000000000000  |\n",
            "|0.00000556000000000000  |\n",
            "|0.00000000000000000000  |\n",
            "|0.00007070000000000000  |\n",
            "|0.00000000000000000000  |\n",
            "|0.00000000000000000000  |\n",
            "|0.00000289000000000000  |\n",
            "|0.00000000000000000000  |\n",
            "|0.00000000000000000000  |\n",
            "|0.00419000000000000000  |\n",
            "|0.00000000000000000000  |\n",
            "|0.00000000000000000000  |\n",
            "|0.00000000000000000000  |\n",
            "|0.00000000000000000000  |\n",
            "|0.00002830000000000000  |\n",
            "|0.00004560000000000000  |\n",
            "|0.00000403000000000000  |\n",
            "|0.00001170000000000000  |\n",
            "|0.00000000000000000000  |\n",
            "|0.00000000000000000000  |\n",
            "+------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "music = music.drop(\"index_id\")"
      ],
      "metadata": {
        "id": "nHme5T95oIfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "music.groupBy(\"track_genre\").count().show(20)\n",
        "\n",
        "print(\"by looking at the output \\n in our TARGET VARIABLE there are so many misleading or false values are there \\n they could lead towards to the inaccurate predictions \\n so we need to clear those rows containing false data.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMsuTbRmoIjL",
        "outputId": "95ac5acb-cb1f-4ce1-980e-38b2a0c8729c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+\n",
            "|   track_genre|count|\n",
            "+--------------+-----+\n",
            "|         anime| 1000|\n",
            "|          folk| 1000|\n",
            "|             3|   23|\n",
            "|     hardstyle| 1000|\n",
            "|         0.576|    1|\n",
            "|   alternative| 1000|\n",
            "|   death-metal| 1000|\n",
            "|        74.077|    1|\n",
            "|detroit-techno| 1000|\n",
            "|           idm| 1000|\n",
            "|       105.188|    1|\n",
            "|         k-pop| 1000|\n",
            "|       j-dance| 1000|\n",
            "|        68.958|    2|\n",
            "|       ambient| 1000|\n",
            "|        guitar|  999|\n",
            "|          goth| 1000|\n",
            "|      cantopop| 1000|\n",
            "|         blues| 1000|\n",
            "|             5|   12|\n",
            "+--------------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "by looking at the output \n",
            " in our TARGET VARIABLE there are so many misleading or false values are there \n",
            " they could lead towards to the inaccurate predictions \n",
            " so we need to clear those rows containing false data.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drop_list = [\"3\", \"0.576\", \"74.077\",\"105.188\",\"68.958\",\"5\",\"68.453\",\"151.539\",\"117.11\",\"76.791\",\"89.01\",\"1\",\"125.262\",\"4\",\"148.759\",\"114.211\",\"7\",\"0.159\",\"0.983\",\"0.103\",\"89.912\",\"0.0898\",\"81.078\",\"60.015\",\"1.50E-05\",\"76.691\",\"95.073\",\"121.165\",\"0.34\",\"134.113\",\"0.114\",\"90.051\",\"91.467\",\"131.721\",\"133.67\",\"10\",\"133.106\",\"-12.753\"]\n",
        "music_df = music.filter(~music.track_genre.isin(drop_list))\n",
        "music_df.groupBy(\"track_genre\").count().show()"
      ],
      "metadata": {
        "id": "IC49dt9cin-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86e07fff-587a-4d49-da99-2d90db39512f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------+-----+\n",
            "|   track_genre|count|\n",
            "+--------------+-----+\n",
            "|         anime| 1000|\n",
            "|          folk| 1000|\n",
            "|     hardstyle| 1000|\n",
            "|   alternative| 1000|\n",
            "|   death-metal| 1000|\n",
            "|detroit-techno| 1000|\n",
            "|           idm| 1000|\n",
            "|         k-pop| 1000|\n",
            "|       j-dance| 1000|\n",
            "|       ambient| 1000|\n",
            "|        guitar|  999|\n",
            "|          goth| 1000|\n",
            "|      cantopop| 1000|\n",
            "|         blues| 1000|\n",
            "|     breakbeat| 1000|\n",
            "|         dance| 1000|\n",
            "|        groove| 1000|\n",
            "|        indian| 1000|\n",
            "|        german|  991|\n",
            "|        french| 1000|\n",
            "+--------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(music_df.show(1))"
      ],
      "metadata": {
        "id": "98r_J0plp8cV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7d796ac-8f53-42e6-ad06-0852f7a15182"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+----------+-----------+------------+------+---+--------+----+-----------+------------+--------+-------+------+--------------+-----------+------------------------+\n",
            "|    artists|album_name|popularity|duration_ms|danceability|energy|key|loudness|mode|speechiness|acousticness|liveness|valence| tempo|time_signature|track_genre|instrumentalness_decimal|\n",
            "+-----------+----------+----------+-----------+------------+------+---+--------+----+-----------+------------+--------+-------+------+--------------+-----------+------------------------+\n",
            "|Gen Hoshino|    Comedy|        73|     230666|       0.676| 0.461|  1|  -6.746|   0|      0.143|      0.0322|   0.358|  0.715|87.917|           4.0|   acoustic|    0.000001010000000...|\n",
            "+-----------+----------+----------+-----------+------------+------+---+--------+----+-----------+------------+--------+-------+------+--------------+-----------+------------------------+\n",
            "only showing top 1 row\n",
            "\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we need to convert our categorical columns into numeric for further operations\n",
        "we will do it using **StringIndexer**"
      ],
      "metadata": {
        "id": "Q9Ksiqe_ZBH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.feature import VectorAssembler"
      ],
      "metadata": {
        "id": "C-YbpBC_p8el"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexer = StringIndexer(inputCol=\"artists\",outputCol=\"artists_Num\")\n",
        "#if any error occurs just uncomment the below line\n",
        "#music_df=music_df.drop(\"artists_Num\")\n",
        "music_df = indexer.fit(music_df).transform(music_df)\n",
        "music_df = music_df.withColumn(\"artists_Num\", col(\"artists_Num\").cast(\"integer\"))"
      ],
      "metadata": {
        "id": "b8JsbDfMp8iH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexer = StringIndexer(inputCol=\"album_name\",outputCol=\"album_name_Num\")\n",
        "#if any error occurs just uncomment the below line\n",
        "#music_df=music_df.drop(\"album_name_Num\")\n",
        "music_df = indexer.fit(music_df).transform(music_df)\n",
        "music_df = music_df.withColumn(\"album_name\", col(\"album_name\").cast(\"integer\"))"
      ],
      "metadata": {
        "id": "RhybfbWjaf0I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now that we have numeric columns ,drop original columns"
      ],
      "metadata": {
        "id": "7IGF87akeEnm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_numeric = music_df.drop(\"artists\",\"album_name\")\n",
        "music_df_numeric.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_Wnkv6KawfF",
        "outputId": "9c59f7cb-b23a-4241-c3cd-40e37ff88d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+------------+------+---+--------+----+-----------+------------+--------+-------+-------+--------------+-----------+------------------------+-----------+--------------+\n",
            "|popularity|duration_ms|danceability|energy|key|loudness|mode|speechiness|acousticness|liveness|valence|  tempo|time_signature|track_genre|instrumentalness_decimal|artists_Num|album_name_Num|\n",
            "+----------+-----------+------------+------+---+--------+----+-----------+------------+--------+-------+-------+--------------+-----------+------------------------+-----------+--------------+\n",
            "|        73|     230666|       0.676| 0.461|  1|  -6.746|   0|      0.143|      0.0322|   0.358|  0.715| 87.917|           4.0|   acoustic|    0.000001010000000...|       2100|        4670.0|\n",
            "|        55|     149610|        0.42| 0.166|  1| -17.235|   1|     0.0763|       0.924|   0.101|  0.267| 77.489|           4.0|   acoustic|    0.000005560000000...|       1492|       12573.0|\n",
            "|        57|     210826|       0.438| 0.359|  0|  -9.734|   1|     0.0557|        0.21|   0.117|   0.12| 76.332|           4.0|   acoustic|    0.000000000000000...|      21261|       42047.0|\n",
            "|        71|     201933|       0.266|0.0596|  0| -18.515|   1|     0.0363|       0.905|   0.132|  0.143| 181.74|           3.0|   acoustic|    0.000070700000000...|       1294|       23988.0|\n",
            "|        82|     198853|       0.618| 0.443|  2|  -9.681|   1|     0.0526|       0.469|  0.0829|  0.167|119.949|           4.0|   acoustic|    0.000000000000000...|       1854|        2762.0|\n",
            "|        58|     214240|       0.688| 0.481|  6|  -8.807|   1|      0.105|       0.289|   0.189|  0.666| 98.017|           4.0|   acoustic|    0.000000000000000...|       6306|       11529.0|\n",
            "|        74|     229400|       0.407| 0.147|  2|  -8.822|   1|     0.0355|       0.857|  0.0913| 0.0765|141.284|           3.0|   acoustic|    0.000002890000000...|       2539|        2185.0|\n",
            "|        80|     242946|       0.703| 0.444| 11|  -9.331|   1|     0.0417|       0.559|  0.0973|  0.712| 150.96|           4.0|   acoustic|    0.000000000000000...|        179|        4195.0|\n",
            "|        74|     189613|       0.625| 0.414|  0|    -8.7|   1|     0.0369|       0.294|   0.151|  0.669|130.088|           4.0|   acoustic|    0.000000000000000...|      11140|        4195.0|\n",
            "|        56|     205594|       0.442| 0.632|  1|   -6.77|   1|     0.0295|       0.426|  0.0735|  0.196| 78.899|           4.0|   acoustic|    0.004190000000000...|       2835|       13076.0|\n",
            "|        74|     244800|       0.627| 0.363|  8|  -8.127|   1|     0.0291|       0.279|  0.0928|  0.301| 99.905|           4.0|   acoustic|    0.000000000000000...|       1237|        2684.0|\n",
            "|        69|     240165|       0.483| 0.303|  4| -10.058|   1|     0.0429|       0.694|   0.115|  0.139|133.406|           3.0|   acoustic|    0.000000000000000...|        179|        5247.0|\n",
            "|        52|     198712|       0.489| 0.314|  7|  -9.245|   0|     0.0331|       0.749|   0.113|  0.607|124.234|           4.0|   acoustic|    0.000000000000000...|      10000|        2345.0|\n",
            "|        62|     248448|       0.691| 0.234|  3|  -6.441|   1|     0.0285|       0.777|    0.12|  0.209| 87.103|           4.0|   acoustic|    0.000000000000000...|       6574|        6580.0|\n",
            "|        56|     188133|       0.755|  0.78|  2|  -6.084|   1|     0.0327|       0.124|   0.121|  0.387|120.004|           4.0|   acoustic|    0.000028300000000...|      17366|       28894.0|\n",
            "|        58|     244986|       0.489| 0.561|  4|  -7.933|   1|     0.0274|         0.2|   0.179|  0.238| 83.457|           3.0|   acoustic|    0.000045600000000...|      11648|       40888.0|\n",
            "|        56|     129750|       0.706| 0.112|  2| -18.098|   1|     0.0391|       0.827|   0.125|  0.414|110.154|           4.0|   acoustic|    0.000004030000000...|        567|       18138.0|\n",
            "|        54|     169728|       0.795|0.0841| 10|  -18.09|   0|     0.0461|       0.742|  0.0853|  0.609| 91.803|           4.0|   acoustic|    0.000011700000000...|        567|       10489.0|\n",
            "|        68|     189613|       0.625| 0.414|  0|    -8.7|   1|     0.0369|       0.294|   0.151|  0.669|130.088|           4.0|   acoustic|    0.000000000000000...|      11140|        4195.0|\n",
            "|        67|     260186|       0.717|  0.32|  3|  -8.393|   1|     0.0283|        0.83|   0.107|  0.322|107.946|           4.0|   acoustic|    0.000000000000000...|       6734|        1184.0|\n",
            "+----------+-----------+------------+------+---+--------+----+-----------+------------+--------+-------+-------+--------------+-----------+------------------------+-----------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# now only thing remaining is to convert our target variable into numeric"
      ],
      "metadata": {
        "id": "A8PiTxwKeYKV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indexer = StringIndexer(inputCol=\"track_genre\",outputCol=\"track_genre_Num\")\n",
        "#if any error occurs just uncomment the below line\n",
        "#music_df_numeric=music_df_numeric.drop(\"track_genre_Num\")\n",
        "music_df_numeric = indexer.fit(music_df_numeric).transform(music_df_numeric)\n",
        "music_df_numeric = music_df_numeric.withColumn(\"track_genre_Num\", col(\"track_genre_Num\").cast(\"integer\"))"
      ],
      "metadata": {
        "id": "iTkGMoHFeSKp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "after converting drop original column"
      ],
      "metadata": {
        "id": "a2gMCLaRffp6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_numeric = music_df_numeric.drop(\"track_genre\")\n",
        "music_df_numeric.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YjkmNYKQd3mw",
        "outputId": "5b6fa853-10d6-4f5f-880e-da3488cdc322"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+-----------+------------+------+---+--------+----+-----------+------------+--------+-------+-------+--------------+------------------------+-----------+--------------+---------------+\n",
            "|popularity|duration_ms|danceability|energy|key|loudness|mode|speechiness|acousticness|liveness|valence|  tempo|time_signature|instrumentalness_decimal|artists_Num|album_name_Num|track_genre_Num|\n",
            "+----------+-----------+------------+------+---+--------+----+-----------+------------+--------+-------+-------+--------------+------------------------+-----------+--------------+---------------+\n",
            "|        73|     230666|       0.676| 0.461|  1|  -6.746|   0|      0.143|      0.0322|   0.358|  0.715| 87.917|           4.0|    0.000001010000000...|       2100|        4670.0|             98|\n",
            "|        55|     149610|        0.42| 0.166|  1| -17.235|   1|     0.0763|       0.924|   0.101|  0.267| 77.489|           4.0|    0.000005560000000...|       1492|       12573.0|             98|\n",
            "|        57|     210826|       0.438| 0.359|  0|  -9.734|   1|     0.0557|        0.21|   0.117|   0.12| 76.332|           4.0|    0.000000000000000...|      21261|       42047.0|             98|\n",
            "|        71|     201933|       0.266|0.0596|  0| -18.515|   1|     0.0363|       0.905|   0.132|  0.143| 181.74|           3.0|    0.000070700000000...|       1294|       23988.0|             98|\n",
            "|        82|     198853|       0.618| 0.443|  2|  -9.681|   1|     0.0526|       0.469|  0.0829|  0.167|119.949|           4.0|    0.000000000000000...|       1854|        2762.0|             98|\n",
            "|        58|     214240|       0.688| 0.481|  6|  -8.807|   1|      0.105|       0.289|   0.189|  0.666| 98.017|           4.0|    0.000000000000000...|       6306|       11529.0|             98|\n",
            "|        74|     229400|       0.407| 0.147|  2|  -8.822|   1|     0.0355|       0.857|  0.0913| 0.0765|141.284|           3.0|    0.000002890000000...|       2539|        2185.0|             98|\n",
            "|        80|     242946|       0.703| 0.444| 11|  -9.331|   1|     0.0417|       0.559|  0.0973|  0.712| 150.96|           4.0|    0.000000000000000...|        179|        4195.0|             98|\n",
            "|        74|     189613|       0.625| 0.414|  0|    -8.7|   1|     0.0369|       0.294|   0.151|  0.669|130.088|           4.0|    0.000000000000000...|      11140|        4195.0|             98|\n",
            "|        56|     205594|       0.442| 0.632|  1|   -6.77|   1|     0.0295|       0.426|  0.0735|  0.196| 78.899|           4.0|    0.004190000000000...|       2835|       13076.0|             98|\n",
            "|        74|     244800|       0.627| 0.363|  8|  -8.127|   1|     0.0291|       0.279|  0.0928|  0.301| 99.905|           4.0|    0.000000000000000...|       1237|        2684.0|             98|\n",
            "|        69|     240165|       0.483| 0.303|  4| -10.058|   1|     0.0429|       0.694|   0.115|  0.139|133.406|           3.0|    0.000000000000000...|        179|        5247.0|             98|\n",
            "|        52|     198712|       0.489| 0.314|  7|  -9.245|   0|     0.0331|       0.749|   0.113|  0.607|124.234|           4.0|    0.000000000000000...|      10000|        2345.0|             98|\n",
            "|        62|     248448|       0.691| 0.234|  3|  -6.441|   1|     0.0285|       0.777|    0.12|  0.209| 87.103|           4.0|    0.000000000000000...|       6574|        6580.0|             98|\n",
            "|        56|     188133|       0.755|  0.78|  2|  -6.084|   1|     0.0327|       0.124|   0.121|  0.387|120.004|           4.0|    0.000028300000000...|      17366|       28894.0|             98|\n",
            "|        58|     244986|       0.489| 0.561|  4|  -7.933|   1|     0.0274|         0.2|   0.179|  0.238| 83.457|           3.0|    0.000045600000000...|      11648|       40888.0|             98|\n",
            "|        56|     129750|       0.706| 0.112|  2| -18.098|   1|     0.0391|       0.827|   0.125|  0.414|110.154|           4.0|    0.000004030000000...|        567|       18138.0|             98|\n",
            "|        54|     169728|       0.795|0.0841| 10|  -18.09|   0|     0.0461|       0.742|  0.0853|  0.609| 91.803|           4.0|    0.000011700000000...|        567|       10489.0|             98|\n",
            "|        68|     189613|       0.625| 0.414|  0|    -8.7|   1|     0.0369|       0.294|   0.151|  0.669|130.088|           4.0|    0.000000000000000...|      11140|        4195.0|             98|\n",
            "|        67|     260186|       0.717|  0.32|  3|  -8.393|   1|     0.0283|        0.83|   0.107|  0.322|107.946|           4.0|    0.000000000000000...|       6734|        1184.0|             98|\n",
            "+----------+-----------+------------+------+---+--------+----+-----------+------------+--------+-------+-------+--------------+------------------------+-----------+--------------+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "music_df_numeric.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_RaKQFWkQ6K",
        "outputId": "7b530943-9fdb-49e0-f243-dc8188191143"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- popularity: string (nullable = true)\n",
            " |-- duration_ms: string (nullable = true)\n",
            " |-- danceability: string (nullable = true)\n",
            " |-- energy: string (nullable = true)\n",
            " |-- key: string (nullable = true)\n",
            " |-- loudness: string (nullable = true)\n",
            " |-- mode: string (nullable = true)\n",
            " |-- speechiness: string (nullable = true)\n",
            " |-- acousticness: string (nullable = true)\n",
            " |-- liveness: string (nullable = true)\n",
            " |-- valence: string (nullable = true)\n",
            " |-- tempo: double (nullable = true)\n",
            " |-- time_signature: double (nullable = true)\n",
            " |-- instrumentalness_decimal: string (nullable = true)\n",
            " |-- artists_Num: integer (nullable = true)\n",
            " |-- album_name_Num: double (nullable = false)\n",
            " |-- track_genre_Num: integer (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "observing above schema there are still so many columns with String type we need to convert them first for the further operations"
      ],
      "metadata": {
        "id": "4XUxLfdZq7AW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import DoubleType\n",
        "# define a UDF to convert multiple string columns to double columns\n",
        "string_to_double = udf(lambda x: float(x) if x else None, DoubleType())\n",
        "string_columns = [\"popularity\", \"duration_ms\", \"danceability\", \"energy\",\"album_name_Num\",\"track_genre_Num\", \"key\", \"loudness\",\"artists_Num\",\"mode\", \"speechiness\", \"acousticness\", \"liveness\", \"valence\",\"instrumentalness_decimal\"]"
      ],
      "metadata": {
        "id": "SPuHyjhVrNWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for column in string_columns:\n",
        "    music_df_numeric = music_df_numeric.withColumn(column + \"\", string_to_double(column))\n",
        "music_df_numeric.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CE6FxjprN1p",
        "outputId": "f37dd5c9-5b47-4963-b6f9-633e140adfab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- popularity: double (nullable = true)\n",
            " |-- duration_ms: double (nullable = true)\n",
            " |-- danceability: double (nullable = true)\n",
            " |-- energy: double (nullable = true)\n",
            " |-- key: double (nullable = true)\n",
            " |-- loudness: double (nullable = true)\n",
            " |-- mode: double (nullable = true)\n",
            " |-- speechiness: double (nullable = true)\n",
            " |-- acousticness: double (nullable = true)\n",
            " |-- liveness: double (nullable = true)\n",
            " |-- valence: double (nullable = true)\n",
            " |-- tempo: double (nullable = true)\n",
            " |-- time_signature: double (nullable = true)\n",
            " |-- instrumentalness_decimal: double (nullable = true)\n",
            " |-- artists_Num: double (nullable = true)\n",
            " |-- album_name_Num: double (nullable = true)\n",
            " |-- track_genre_Num: double (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import isnan, when, count, col\n",
        "#music_df_numeric.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in music_df_numeric.columns]).show()\n",
        "# drop rows with missing values\n",
        "music_df_numeric = music_df_numeric.dropna()"
      ],
      "metadata": {
        "id": "eq-5T1_N1AH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lets check correlation of every feature with our target variable"
      ],
      "metadata": {
        "id": "HR-Lt4--gdyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the correlation coefficients with target columns\n",
        "from pyspark.sql.functions import corr\n",
        "def print_correlation_with_target(music_df_numeric, target):\n",
        "    columns = [\"popularity\", \"duration_ms\", \"danceability\", \"energy\", \"key\", \"loudness\",\"mode\", \"speechiness\", \"acousticness\", \"liveness\", \"valence\",\"instrumentalness_decimal\",\"artists_Num\",\"album_name_Num\",\"track_genre_Num\"]\n",
        "    for column in columns:\n",
        "      correlation = music_df_numeric.select(corr(column, target)).collect()[0][0]\n",
        "      print(f\"{column}\\t correlation with target\\t : {correlation}\")\n",
        "target=\"track_genre_Num\"\n",
        "print_correlation_with_target(music_df_numeric,target)"
      ],
      "metadata": {
        "id": "6Wzkomejgcgc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "279e8693-fe7a-42c9-9a22-5d08d74fc291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Py4JJavaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-df3630d890a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{column}\\t correlation with target\\t : {correlation}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"track_genre_Num\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mprint_correlation_with_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmusic_df_numeric\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-56-df3630d890a3>\u001b[0m in \u001b[0;36mprint_correlation_with_target\u001b[0;34m(music_df_numeric, target)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"popularity\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"duration_ms\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"danceability\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"energy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"key\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"loudness\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"speechiness\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"acousticness\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"liveness\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"valence\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"instrumentalness_decimal\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"artists_Num\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"album_name_Num\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"track_genre_Num\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcolumn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mcorrelation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmusic_df_numeric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{column}\\t correlation with target\\t : {correlation}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"track_genre_Num\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mcollect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    815\u001b[0m         \"\"\"\n\u001b[1;32m    816\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSCCallSiteSync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m             \u001b[0msock_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollectToPython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_load_from_socket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msock_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchedSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCPickleSerializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1322\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0mconverted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjava_exception\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOUTPUT_CONVERTER\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway_client\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0manswer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mREFERENCE_TYPE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m                 raise Py4JJavaError(\n\u001b[0m\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     format(target_id, \".\", name), value)\n",
            "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o824.collectToPython.\n: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 44.0 failed 1 times, most recent failure: Lost task 0.0 in stage 44.0 (TID 61) (d2028b7965c8 executor driver): org.apache.spark.SparkException: Failed to execute user defined function (StringIndexerModel$$Lambda$3721/0x000000084154b040: (string) => double)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala:190)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.ContextAwareIterator.hasNext(ContextAwareIterator.scala:39)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1160)\n\tat scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1176)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1214)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.writeIteratorToStream(PythonUDFRunner.scala:53)\n\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:431)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:265)\nCaused by: org.apache.spark.SparkException: StringIndexer encountered NULL value. To handle or skip NULLS, try setting StringIndexer.handleInvalid.\n\tat org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1(StringIndexer.scala:396)\n\tat org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1$adapted(StringIndexer.scala:391)\n\t... 20 more\n\nDriver stacktrace:\n\tat org.apache.spark.scheduler.DAGScheduler.failJobAndIndependentStages(DAGScheduler.scala:2672)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2(DAGScheduler.scala:2608)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$abortStage$2$adapted(DAGScheduler.scala:2607)\n\tat scala.collection.mutable.ResizableArray.foreach(ResizableArray.scala:62)\n\tat scala.collection.mutable.ResizableArray.foreach$(ResizableArray.scala:55)\n\tat scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:49)\n\tat org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:2607)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGScheduler.$anonfun$handleTaskSetFailed$1$adapted(DAGScheduler.scala:1182)\n\tat scala.Option.foreach(Option.scala:407)\n\tat org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:1182)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:2860)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2802)\n\tat org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:2791)\n\tat org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:49)\nCaused by: org.apache.spark.SparkException: Failed to execute user defined function (StringIndexerModel$$Lambda$3721/0x000000084154b040: (string) => double)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors$.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala:190)\n\tat org.apache.spark.sql.errors.QueryExecutionErrors.failedExecuteUserDefinedFunctionError(QueryExecutionErrors.scala)\n\tat org.apache.spark.sql.catalyst.expressions.GeneratedClass$GeneratedIteratorForCodegenStage1.processNext(Unknown Source)\n\tat org.apache.spark.sql.execution.BufferedRowIterator.hasNext(BufferedRowIterator.java:43)\n\tat org.apache.spark.sql.execution.WholeStageCodegenExec$$anon$1.hasNext(WholeStageCodegenExec.scala:760)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat org.apache.spark.ContextAwareIterator.hasNext(ContextAwareIterator.scala:39)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator$GroupedIterator.takeDestructively(Iterator.scala:1160)\n\tat scala.collection.Iterator$GroupedIterator.go(Iterator.scala:1176)\n\tat scala.collection.Iterator$GroupedIterator.fill(Iterator.scala:1214)\n\tat scala.collection.Iterator$GroupedIterator.hasNext(Iterator.scala:1217)\n\tat scala.collection.Iterator$$anon$10.hasNext(Iterator.scala:460)\n\tat scala.collection.Iterator.foreach(Iterator.scala:943)\n\tat scala.collection.Iterator.foreach$(Iterator.scala:943)\n\tat scala.collection.AbstractIterator.foreach(Iterator.scala:1431)\n\tat org.apache.spark.api.python.PythonRDD$.writeIteratorToStream(PythonRDD.scala:307)\n\tat org.apache.spark.sql.execution.python.PythonUDFRunner$$anon$1.writeIteratorToStream(PythonUDFRunner.scala:53)\n\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.$anonfun$run$1(PythonRunner.scala:431)\n\tat org.apache.spark.util.Utils$.logUncaughtExceptions(Utils.scala:2066)\n\tat org.apache.spark.api.python.BasePythonRunner$WriterThread.run(PythonRunner.scala:265)\nCaused by: org.apache.spark.SparkException: StringIndexer encountered NULL value. To handle or skip NULLS, try setting StringIndexer.handleInvalid.\n\tat org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1(StringIndexer.scala:396)\n\tat org.apache.spark.ml.feature.StringIndexerModel.$anonfun$getIndexer$1$adapted(StringIndexer.scala:391)\n\t... 20 more\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mel1TjXiQhx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gzCmZVOvQhzt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "icho61H3QiTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4lsLPOlZQica"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oimqnOQKQifZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kni2T2bTQih0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A1RdooebQikb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UquJ6syZQinB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xzMoKOSFQipX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CVsQ4GLpQirk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "07J06RgRQit9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZPrhSXBgQiwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZZakb_wJQkSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7BOyEuyZQkVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gs79kivTQkYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ain19U1QQkfm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Now, lets build RANDOM FOREST Classifier model"
      ],
      "metadata": {
        "id": "Z-Hk9a_zgNLs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "# Define the input columns to the model\n",
        "input_cols = string_columns = [\"popularity\", \"duration_ms\", \"danceability\", \"energy\",\"album_name_Num\", \"key\", \"loudness\",\"artists_Num\",\"mode\", \"speechiness\", \"acousticness\", \"liveness\", \"valence\",\"instrumentalness_decimal\"]\n",
        "# Create a VectorAssembler object to transform input features into a single vector\n",
        "assembler = VectorAssembler(inputCols=input_cols, outputCol='features')"
      ],
      "metadata": {
        "id": "CXUrPGSz2jlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transform the input data using VectorAssembler\n",
        "data = assembler.transform(music_df_numeric).select('features', 'track_genre_Num')"
      ],
      "metadata": {
        "id": "QoYxEciW3XVA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=1234)"
      ],
      "metadata": {
        "id": "md0wXqEE30sf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "\n",
        "# Define the random forest classifier model\n",
        "rf = RandomForestClassifier(featuresCol=\"features\", labelCol=\"track_genre_Num\", numTrees=100)\n",
        "# Train the model on the training data\n",
        "rf_model = rf.fit(train_data)\n",
        "# Make predictions on the test data\n",
        "predictions_by_RF = rf_model.transform(test_data)\n",
        "#Evaluate the model using the accuracy metric\n",
        "evaluator = BinaryClassificationEvaluator(labelCol=\"track_genre_Num\", metricName=\"areaUnderROC\")\n",
        "accuracy = evaluator.evaluate(predictions_by_RF)\n",
        "print(\"Accuracy = {:.2f}\".format(accuracy))\n"
      ],
      "metadata": {
        "id": "ekRpUWKLfX2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mE3iGdl-f9Gm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}